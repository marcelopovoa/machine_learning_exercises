{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb2778bf",
   "metadata": {},
   "source": [
    "# Estimating House Prices (Multiple Regression) - Manual Gradient Descent Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd09b2b",
   "metadata": {},
   "source": [
    "Regression estimating house prices based on previous house sales, using features like house size (sqft), number of bathrooms and so on...\n",
    "We manually calculate the Gradient Descent of the regression algorithm for multiple regression cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf2e72",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7006810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67fdbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb51780",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = turicreate.SFrame('../data/home_data.sframe/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f7b7e6",
   "metadata": {},
   "source": [
    "### Creating a helper function to convert SFrame to numpy matrices, leveraging the streghts of numpy and turicreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535d3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 # this is how you add a constant column to an SFrame\n",
    "    \n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    \n",
    "    # select the columns of data_SFrame given by the features list into the SFrame features_sframe (now including constant):\n",
    "    features_sframe = data_sframe[features]\n",
    "    \n",
    "    # the following line will convert the features_SFrame into a numpy matrix:\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "    \n",
    "    # assign the column of data_sframe associated with the output to the SArray output_sarray\n",
    "    output_sarray = data_sframe[output]\n",
    "    \n",
    "    # the following will convert the SArray into a numpy array by first converting it to a list\n",
    "    output_array = output_sarray.to_numpy()\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b59a6c",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c83a24c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1180.0\n",
      "221900.0\n",
      "[1.00e+00 1.18e+03]\n",
      "221900.0\n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(sales, ['sqft_living'], 'price') # the [] around 'sqft_living' makes it a list\n",
    "print(sales[0]['sqft_living'])\n",
    "print(sales[0]['price'])\n",
    "print(example_features[0,:]) # this accesses the first row of the data the ':' indicates 'all columns'\n",
    "print(example_output[0]) # and the corresponding output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df5473d",
   "metadata": {},
   "source": [
    "# Predicting output given regression weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a50c8acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce387d9",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61953b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181.0\n",
      "2571.0\n"
     ]
    }
   ],
   "source": [
    "my_weights = np.array([1., 1.]) # the example weights\n",
    "my_features = example_features[0,] # we'll use the first data point\n",
    "test_predictions = predict_output(example_features, my_weights)\n",
    "print (test_predictions[0]) # should be 1181.0\n",
    "print (test_predictions[1]) # should be 2571.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f20a3",
   "metadata": {},
   "source": [
    "# Creating the derivative function for gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b60f9138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    # Assume that errors and feature are both numpy arrays of the same length (number of data points)\n",
    "    # compute twice the dot product of these vectors as 'derivative' and return the value\n",
    "    \n",
    "    # This is the RSS derivative\n",
    "    derivative = 2 * np.dot(errors, feature)\n",
    "    \n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86a171a",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "360e11ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-23345850022.0\n",
      "-23345850022.0\n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(sales, ['sqft_living'], 'price') \n",
    "my_weights = np.array([0., 0.]) # this makes all the predictions 0\n",
    "test_predictions = predict_output(example_features, my_weights) \n",
    "# just like SFrames 2 numpy arrays can be elementwise subtracted with '-': \n",
    "errors = test_predictions - example_output # prediction errors in this case is just the -example_output\n",
    "feature = example_features[:,0] # let's compute the derivative with respect to 'constant', the \":\" indicates \"all rows\"\n",
    "derivative = feature_derivative(errors, feature)\n",
    "print (derivative)\n",
    "print (-np.sum(example_output)*2) # should be the same as derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95846b6",
   "metadata": {},
   "source": [
    "# Creating the Gradient Descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8ff8380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42635e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False \n",
    "    weights = np.array(initial_weights) # make sure it's a numpy array\n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights using your predict_output() function\n",
    "        predictions = predict_output(feature_matrix, weights)\n",
    "        \n",
    "        # compute the errors as predictions - output\n",
    "        errors = predictions - output\n",
    "        \n",
    "        gradient_sum_squares = 0 # initialize the gradient sum of squares\n",
    "        \n",
    "        # while we haven't reached the tolerance yet, update each feature's weight\n",
    "        for i in range(len(weights)): # loop over each weight\n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            derivative = feature_derivative(errors, feature_matrix[:,i])\n",
    "            \n",
    "            # add the squared value of the derivative to the gradient sum of squares (for assessing convergence)\n",
    "            gradient_sum_squares = gradient_sum_squares + derivative**2 #np.dot(derivative,derivative) # #np.dot(derivative,derivative)\n",
    "            \n",
    "            # subtract the step size times the derivative from the current weight\n",
    "            weights[i] = weights[i] - step_size*derivative\n",
    "            \n",
    "        # compute the square-root of the gradient sum of squares to get the gradient magnitude:\n",
    "        gradient_magnitude = sqrt(gradient_sum_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524e91cd",
   "metadata": {},
   "source": [
    "# 1. Now testing Gradient Descent on a single (one feature) regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b2c5256",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = sales.random_split(.8,seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1d3711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test out the gradient descent\n",
    "features_1 = ['sqft_living']\n",
    "my_output = 'price'\n",
    "(feature_matrix_1, output_1) = get_numpy_data(train_data, features_1, my_output)\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99086e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-46999.88716555    281.91211912]\n"
     ]
    }
   ],
   "source": [
    "gradient_weights_1 = regression_gradient_descent(feature_matrix_1, output_1, initial_weights, step_size, tolerance)\n",
    "print(gradient_weights_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ff6291",
   "metadata": {},
   "source": [
    "### What is the value of the sqft_living weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bcac17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281.91211911641625"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_weights_1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc90642",
   "metadata": {},
   "source": [
    "### Predicting all test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08c79e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_feature_matrix_1, test_output_1) = get_numpy_data(test_data, features_1, my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13823fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_1 = predict_output(test_feature_matrix_1, gradient_weights_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a95fe5",
   "metadata": {},
   "source": [
    "### Model 1 predicted house price for the test set 1st house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55708ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356134.4431709297\n"
     ]
    }
   ],
   "source": [
    "print (test_predictions_1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fc8689",
   "metadata": {},
   "source": [
    "### RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "112b5110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275400047593155.7\n"
     ]
    }
   ],
   "source": [
    "rss_model_1 = sum((test_predictions_1 - test_output_1)*(test_predictions_1 - test_output_1))\n",
    "print(rss_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f91ce4",
   "metadata": {},
   "source": [
    "# 2. Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87ea482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_2 = ['sqft_living', 'sqft_living15'] # sqft_living15 is the average squarefeet for the nearest 15 neighbors. \n",
    "my_output = 'price'\n",
    "(feature_matrix_2, output_2) = get_numpy_data(train_data, features_2, my_output)\n",
    "initial_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b0dafba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.99999688e+04  2.45072603e+02  6.52795277e+01]\n"
     ]
    }
   ],
   "source": [
    "gradient_weights_2 = regression_gradient_descent(feature_matrix_2, output_2, initial_weights, step_size, tolerance)\n",
    "print(gradient_weights_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd7bb4",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "575b9e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366651.4120365591\n",
      "762662.3978616422\n"
     ]
    }
   ],
   "source": [
    "(test_feature_matrix_2, test_output_2) = get_numpy_data(test_data, features_2, my_output)\n",
    "test_predictions_2 = predict_output(test_feature_matrix_2, gradient_weights_2)\n",
    "print (test_predictions_2[0])\n",
    "print (test_predictions_2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c1cc5a",
   "metadata": {},
   "source": [
    "### RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bae1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_model_2 = sum((test_predictions_2 - test_output_2)*(test_predictions_2 - test_output_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e569675c",
   "metadata": {},
   "source": [
    "### Model 2 predicted house price for the test set 1st house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47c71665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366651.4120365591\n"
     ]
    }
   ],
   "source": [
    "print (test_predictions_2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9466037f",
   "metadata": {},
   "source": [
    "### Test set 1st house real price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67b12f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310000.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output_1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e275d2",
   "metadata": {},
   "source": [
    "# Which estimation was closer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4ac1910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-46134.44317092968"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output_1[0] - test_predictions_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c478e82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-56651.41203655908"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output_2[0] - test_predictions_2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feccc3d1",
   "metadata": {},
   "source": [
    "Model 1 was closer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08adfffb",
   "metadata": {},
   "source": [
    "# Which model had lower RSS on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d064089d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rss_model_1 > rss_model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f38228a",
   "metadata": {},
   "source": [
    "Model 2 had lower RSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d948a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_specialization_37",
   "language": "python",
   "name": "ml_specialization_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
